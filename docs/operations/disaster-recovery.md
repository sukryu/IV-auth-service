# 재해 복구 계획 (Disaster Recovery Plan)

본 문서는 **ImmersiVerse Authentication Service**의 재해 복구 계획(Disaster Recovery, DR)에 대해 설명합니다. DR 계획은 예상치 못한 장애, 자연재해, 보안 사고 등으로 인한 데이터 손실 및 서비스 중단 상황에서 신속하게 시스템을 복구하고, 비즈니스 연속성을 보장하기 위한 절차와 책임을 명시합니다.

---

## 1. 목표 및 범위

### 1.1 목표

- **데이터 무결성 및 보안 유지**: 백업 및 복구 절차를 통해 데이터 손실(RPO: 최대 5분 이내) 최소화
- **서비스 복구 시간**: 장애 발생 시 15분 이내(또는 서비스 중요도에 따라 다르게) 복구(RTO)
- **비즈니스 연속성 보장**: 장애 발생 시 최소한의 다운타임으로 서비스를 재개하여 사용자 불편 최소화

### 1.2 적용 범위

- **대상 시스템**:
  - PostgreSQL 데이터베이스 (users, platform_accounts, token_blacklist, audit_logs 등)
  - 인증 관련 캐싱(Redis) 및 메시징(Kafka) 시스템
  - Authentication Service 애플리케이션 컨테이너
- **재해 시나리오**:
  - 단일 인스턴스 장애 및 다중 인스턴스 장애
  - DB 장애(데이터 손실, 연결 문제)
  - 네트워크 장애(클러스터 내/외부 통신 단절)
  - 보안 사고(데이터 유출, 내부 침해)

---

## 2. 재해 복구 목표 (RPO / RTO)

- **RPO (Recovery Point Objective)**: 최대 5분 이내 – 최신 데이터 손실이 5분 분량을 넘지 않도록 WAL 아카이빙 및 증분 백업 적용
- **RTO (Recovery Time Objective)**: 15분 이내 – 장애 발생 후 15분 이내에 서비스를 정상 상태로 복구

---

## 3. 재해 복구 구성 요소

### 3.1 백업 시스템

- **전체 백업**: 주간 전체 백업(pg_basebackup 또는 pg_dump)을 통해 데이터베이스 전체 스냅샷 보관
- **증분 백업 & WAL 아카이빙**: 지속적인 데이터 변경 사항을 WAL 파일로 아카이빙하여 PITR(Point-In-Time Recovery) 지원
- **클라우드 스토리지**: 오프사이트 백업(예: AWS S3, Glacier)을 통해 물리적 장애에 대비

### 3.2 복구 인프라

- **다중 리전 배포**: Primary/Secondary/Tertiary 클러스터 구성(예: AWS, Azure, GCP)으로 재해 시 자동 페일오버 지원
- **자동 복구 스크립트**: 백업 파일에서 DB를 복원하는 스크립트와 복구 절차를 자동화하여 신속한 복구 가능
- **Kubernetes**: 장애 시 컨테이너 재배포 및 서비스 복구를 위한 HPA, ReplicaSet, Pod Disruption Budget 등 활용

---

## 4. 재해 복구 절차

### 4.1 사전 준비

- **백업 모니터링**: 백업 작업의 성공 여부, 백업 파일 무결성, 저장 공간 모니터링
- **정기 복구 테스트**: 월간 또는 분기별로 재해 복구 시나리오를 테스트하여 RPO, RTO 목표 달성 여부 검증
- **문서화**: 모든 복구 절차와 테스트 결과를 문서화하고, 최신 상태로 유지

### 4.2 장애 발생 시 대응 절차

1. **장애 감지 및 초기 대응**
   - 모니터링 도구(Prometheus, Grafana, Alertmanager)를 통해 장애 감지
   - 재해 복구 팀(Incident Commander, 기술 대응팀, 보안 담당자) 즉시 소집
   - 장애 범위 파악(데이터베이스, 네트워크, 애플리케이션)

2. **서비스 격리**
   - 장애 시스템을 격리하여 추가 피해 방지
   - 클러스터 내 또는 외부로부터 해당 시스템 접근 차단

3. **백업 복원 절차 실행**
   - **전체 복원**: 최신 전체 백업과 증분(WAL) 파일을 사용해 데이터베이스 복원
   - **PITR**: 특정 시점으로 복구가 필요한 경우, recovery.conf(또는 postgresql.conf, standby.signal)를 설정하여 PITR 수행
   - **논리 복원**: pg_dump로 생성된 백업 파일을 사용하여 논리적 복원 수행 (데이터가 완전히 손실된 경우)

4. **시스템 재시작 및 검증**
   - 복원된 데이터베이스 및 관련 서비스를 재시작
   - 서비스 헬스체크(Probe), 로그, 애플리케이션 상태를 모니터링하여 정상 동작 확인
   - 복구 완료 후 최종 사용자에게 공지

5. **사후 분석 및 보고**
   - 장애 원인 분석(Root Cause Analysis, RCA) 수행
   - 복구 절차 및 대응 시간 평가, 개선 방안 도출
   - 사고 보고서 작성 후 팀 내 공유 및 문서 업데이트

---

## 5. 재해 복구 테스트

- **정기 DR Drill**:
  - 분기별 전체 시스템 복구 시뮬레이션 실시
  - 다양한 시나리오(단일 장애, 다중 장애, 네트워크 장애) 테스트
- **테스트 항목**:
  - 백업 파일 무결성 및 복원 성공률
  - 복구 시간 측정(RTO 목표 달성 여부)
  - 데이터 손실(RPO 측정) 및 일관성 확인
- **피드백**:
  - 테스트 결과를 분석하여 복구 절차, 백업 전략, 모니터링 체계를 개선

---

## 6. 책임 및 역할

- **재해 복구 팀 구성**:
  - **Incident Commander**: 전체 재해 복구 절차 지휘 및 최종 의사 결정
  - **기술 대응팀**: 데이터베이스 복원, 시스템 재배포, 네트워크 재구성 담당
  - **보안 담당자**: 장애 원인 분석, 보안 점검, 침해 대응
  - **커뮤니케이션 담당자**: 내부, 외부 이해관계자(사용자, 규제기관) 통지 및 업데이트

- **역할 분담**:
  - 각 팀은 사전에 역할과 책임을 명확히 정의하고, 정기적으로 훈련 및 DR 테스트를 통해 준비 상태를 점검

---

## 7. 결론

**재해 복구 계획**은 **Authentication Service**의 안정적 운영을 위해 필수적입니다. 주요 내용은 다음과 같습니다:

1. **백업 전략**: 정기 전체 백업, 증분 백업(WAL 아카이빙), 오프사이트 저장
2. **복구 절차**: 장애 감지 → 서비스 격리 → 백업 복원(PITR 및 논리 복원) → 시스템 재시작 및 검증 → 사후 분석
3. **목표**: RPO 5분, RTO 15분 이내 복구
4. **정기 테스트**: DR Drill을 통해 재해 복구 준비 상태 점검 및 개선
5. **책임 분담**: 재해 복구 팀 구성 및 역할 명확화

이 가이드를 준수하여 예상치 못한 장애 상황에서도 신속하고 안전하게 시스템을 복구하고, 사용자와 비즈니스 연속성을 보장할 수 있도록 하시기 바랍니다.

---